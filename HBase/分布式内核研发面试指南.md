# 分布式(hadoop)内核研发面试指南

最近一直在看简历，面试同学，发现符合要求的很少。本文是同学们进入阿里云等公司的hadoop内核研发岗位的一个指引，需要具备哪些要求，如果不具备则可以往这方面努力。

如果 以下的问题不能很好回答，还是多多学习啊。 如果很好回答，对阿里云有兴趣，欢迎找我。

# 面试：
## 基础能力
这里涉及一般为
- 语言基础知识（一般需要在某语言2年以上经验）
  - 比如：JVM的GC算法，JAVA多线程并发机制，线程安全机制，OOM咋办，core了咋办
- 算法基础知识，冒泡排序、链表、树、线性回归……
- 分布式理论：数据分布方式、Lease机制、日志技术、两阶段提交、CAP理论、Quorum机制
- 操作系统
……

## 复杂工程能力
- 就是有没有做过，多人协作的项目
- 你在其中什么角色？ 一般项目有啥难点，遇到难点怎么办？

##  逻辑思维能力及表达能力
-  考查思维，思路。需要清楚的回答上述的一些问题，不卑不亢。

## 潜力
- 就是发展潜力，如果人比较有冲劲，思维比较活跃，目标明确，对未来规划也比较明确，潜力就比较大

## 稳定性（我们更加看重持续发展的同学，不是打一枪就跑了）
- 为什么你要从这家公司离职？
- 你打算进来，2年后，你想有什么样的改变？

## hadoop相关（专家级，一般是开放式的）
比如：
- 分析时数据倾斜了怎么办？
- hdfs写的链路是啥？
- 集群的利用率不高，为什么？怎么调查？
- hbase二级索引是咋回事情？
- 数据高可靠，服务高可用怎么做？
- system占用率比较高，一般啥原因？
- 如果让你设计一个spark，你打算怎么设计？
- 流式计算怎么流控？
- 实时计算与离线怎么混合部署？
- 一车分布式理论的知识？

## 笔试：
主要考察编码能力，一般来讲，经常写代码的同学可能比较上手。
一般为5个题目，其中有2个算法题目。笔试过的同学80%都说比较简单，但是做起来就是不太理想。这个要注意平时写代码要记住关键的词（因为写代码没有自动补全，基本就是纸上或者在记事本上写的）


## 加分项
- 一直在写技术博客，比如：spark源码分析
- 参与社区项目开发，比如：贡献spark、hbase源码
- 发表顶级论文

#### 社群
技术交流钉钉大群 阿里云 HBase+Spark社区 【强烈推荐！】 群内每周进行群直播技术分享及问答
- 加入方式1：点击link申请加入 https://dwz.cn/Fvqv066s

详情请阅读原文：https://yq.aliyun.com/articles/67000
